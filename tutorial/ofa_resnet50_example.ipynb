{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ofa resnet50\n",
    "from ofa.model_zoo import ofa_net\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "#from matplotlib import pyplot as plt\n",
    "from ofa.nas.search_algorithm import EvolutionFinder\n",
    "\n",
    "\n",
    "ofa_network = ofa_net('ofa_resnet50', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /home/panyj/.ofa/ofa_resnet50_acc_predictor.pth\n",
      "The accuracy predictor is ready!\n",
      "AccuracyPredictor(\n",
      "  (layers): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=82, out_features=400, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=400, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=400, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Linear(in_features=400, out_features=1, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# accuracy predictor\n",
    "import torch\n",
    "from ofa.nas.accuracy_predictor import AccuracyPredictor, ResNetArchEncoder\n",
    "from ofa.utils import download_url\n",
    "\n",
    "image_size_list = [128, 144, 160, 176, 192, 224, 240, 256]\n",
    "arch_encoder = ResNetArchEncoder(\n",
    "\timage_size_list=image_size_list, depth_list=ofa_network.depth_list, expand_list=ofa_network.expand_ratio_list,\n",
    "    width_mult_list=ofa_network.width_mult_list, base_depth_list=ofa_network.BASE_DEPTH_LIST\n",
    ")\n",
    "\n",
    "acc_predictor_checkpoint_path = download_url(\n",
    "    'https://hanlab.mit.edu/files/OnceForAll/tutorial/ofa_resnet50_acc_predictor.pth',\n",
    "    model_dir='~/.ofa/',\n",
    ")\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "acc_predictor = AccuracyPredictor(arch_encoder, 400, 3,\n",
    "                                  checkpoint_path=acc_predictor_checkpoint_path, device=device)\n",
    "\n",
    "print('The accuracy predictor is ready!')\n",
    "print(acc_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build efficiency predictor\n",
    "from ofa.nas.efficiency_predictor import ResNet50FLOPsModel\n",
    "\n",
    "efficiency_predictor = ResNet50FLOPsModel(ofa_network)\n",
    "\n",
    "from ofa.nas.memory_predictor import ResNet50WorkingMemModel \n",
    "memory_predictor_baseline = ResNet50WorkingMemModel(ofa_network, 0)\n",
    "memory_predictor_ideal = ResNet50WorkingMemModel(ofa_network, 1)\n",
    "memory_predictor_self = ResNet50WorkingMemModel(ofa_network, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ImageNet dataset files are ready.\n"
     ]
    }
   ],
   "source": [
    "# path to the ImageNet dataset\n",
    "imagenet_data_path = '/data2/jiecaoyu/imagenet/imgs/'\n",
    "print('The ImageNet dataset files are ready.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ImageNet dataloader is ready.\n"
     ]
    }
   ],
   "source": [
    "# The following function build the data transforms for test\n",
    "def build_val_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(int(math.ceil(size / 0.875))),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(\n",
    "        root=os.path.join(imagenet_data_path, 'val'),\n",
    "        transform=build_val_transform(224)\n",
    "    ),\n",
    "    batch_size=250,  # test batch size\n",
    "    shuffle=True,\n",
    "    num_workers=12,  # number of workers for the data loader\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "print('The ImageNet dataloader is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyper-parameters for the evolutionary search process\n",
    "    You can modify these hyper-parameters to see how they influence the final ImageNet accuracy of the search sub-net.\n",
    "\"\"\"\n",
    "FLOPs_constraint = 2000  # MFLOPs\n",
    "workingmem_constraint = 400 # KB\n",
    "P = 100  # The size of population in each generation\n",
    "N = 200  # How many generations of population to be searched\n",
    "r = 0.25  # The ratio of networks that are used as parents for next generation\n",
    "params = {\n",
    "    #'constraint_type': target_hardware, # Let's do FLOPs-constrained search\n",
    "    #'efficiency_constraint': FLOPs_constraint,\n",
    "    'mutate_prob': 0.1, # The probability of mutation in evolutionary search\n",
    "    'mutation_ratio': 0.5, # The ratio of networks that are generated through mutation in generation n >= 2.\n",
    "    'efficiency_predictor': efficiency_predictor, # To use a predefined efficiency predictor.\n",
    "    'accuracy_predictor': acc_predictor, # To use a predefined accuracy_predictor predictor.\n",
    "    'memory_predictor': memory_predictor_baseline, # To use a predefined working memory predictor\n",
    "    'population_size': P,\n",
    "    'max_time_budget': N,\n",
    "    'parent_ratio': r,\n",
    "}\n",
    "\n",
    "# build the evolution finder\n",
    "finder = EvolutionFinder(**params)\n",
    "\n",
    "# start searching\n",
    "result_lis = []\n",
    "st = time.time()\n",
    "best_valids, best_info = finder.run_evolution_search(FLOPs_constraint, workingmem_constraint, verbose=True)\n",
    "result_lis.append(best_info)\n",
    "ed = time.time()\n",
    "print('Found best architecture with FLOPS <= %.2f M and working mem <= %.2f in %.2f seconds! '\n",
    "      'It achieves %.2f%s predicted accuracy ' %\n",
    "      (FLOPs_constraint, workingmem_constraint, ed-st, best_info[0] * 100, '%'))\n",
    "\n",
    "# visualize the architecture of the searched sub-net\n",
    "_, net_config, FLOPS, workingmem = best_info\n",
    "ofa_network.set_active_subnet(w=net_config['w'], d=net_config['d'], e=net_config['e'])\n",
    "print('Architecture of the searched sub-net:')\n",
    "print(ofa_network.module_str)\n",
    "print('FLOPS',FLOPS,'workingmem', workingmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FLOPs_constraint = 2000  # MFLOPs\n",
    "workingmem_constraint = 400 # KB\n",
    "P = 100  # The size of population in each generation\n",
    "N = 200  # How many generations of population to be searched\n",
    "r = 0.25  # The ratio of networks that are used as parents for next generation\n",
    "params = {\n",
    "    #'constraint_type': target_hardware, # Let's do FLOPs-constrained search\n",
    "    #'efficiency_constraint': FLOPs_constraint,\n",
    "    'mutate_prob': 0.1, # The probability of mutation in evolutionary search\n",
    "    'mutation_ratio': 0.5, # The ratio of networks that are generated through mutation in generation n >= 2.\n",
    "    'efficiency_predictor': efficiency_predictor, # To use a predefined efficiency predictor.\n",
    "    'accuracy_predictor': acc_predictor, # To use a predefined accuracy_predictor predictor.\n",
    "    'memory_predictor': memory_predictor_ideal, # To use a predefined working memory predictor\n",
    "    'population_size': P,\n",
    "    'max_time_budget': N,\n",
    "    'parent_ratio': r,\n",
    "}\n",
    "\n",
    "# build the evolution finder\n",
    "finder = EvolutionFinder(**params)\n",
    "\n",
    "# start searching\n",
    "result_lis = []\n",
    "st = time.time()\n",
    "best_valids, best_info = finder.run_evolution_search(FLOPs_constraint, workingmem_constraint, verbose=True)\n",
    "result_lis.append(best_info)\n",
    "ed = time.time()\n",
    "print('Found best architecture with FLOPS <= %.2f M and working mem <= %.2f in %.2f seconds! '\n",
    "      'It achieves %.2f%s predicted accuracy ' %\n",
    "      (FLOPs_constraint, workingmem_constraint, ed-st, best_info[0] * 100, '%'))\n",
    "\n",
    "# visualize the architecture of the searched sub-net\n",
    "_, net_config, FLOPS, workingmem = best_info\n",
    "ofa_network.set_active_subnet(w=net_config['w'], d=net_config['d'], e=net_config['e'])\n",
    "print('Architecture of the searched sub-net:')\n",
    "print(ofa_network.module_str)\n",
    "print('FLOPS',FLOPS,'workingmem', workingmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate random population...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8e9f2d7e7632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mresult_lis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mbest_valids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evolution_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLOPs_constraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkingmem_constraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mresult_lis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0med\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/search_algorithm/evolution.py\u001b[0m in \u001b[0;36mrun_evolution_search\u001b[0;34m(self, latency_constraint, workingmem_constraint, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generate random population...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                         \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mefficiency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkingmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_valid_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatency_constraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkingmem_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                         \u001b[0mchild_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0mefficiency_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficiency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/search_algorithm/evolution.py\u001b[0m in \u001b[0;36mrandom_valid_sample\u001b[0;34m(self, latency_constraint, workingmem_constraint)\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mefficiency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficiency_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_efficiency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0mworkingmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_workingmem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mefficiency\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlatency_constraint\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mworkingmem\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mworkingmem_constraint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mefficiency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkingmem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/memory_predictor/__init__.py\u001b[0m in \u001b[0;36mget_workingmem\u001b[0;34m(self, arch_dict)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_workingmem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mactive_net_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_active_subnet_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mResNet50WorkingMemTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_workingmem_given_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_net_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/memory_predictor/mem_predictor.py\u001b[0m in \u001b[0;36mcount_workingmem_given_config\u001b[0;34m(net_config, image_size, type)\u001b[0m\n\u001b[1;32m    363\u001b[0m \t\t\t\tlayer = Conv_layer_param('input_stem', image_size, image_size, in_channel, layer_config['kernel_size'],\n\u001b[1;32m    364\u001b[0m \t\t\t\t\tlayer_config['padding'], layer_config['stride'], out_image_size, out_image_size, out_channel)\n\u001b[0;32m--> 365\u001b[0;31m                                 \u001b[0mworkingmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkingmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_selfloop_conv_mem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                                 \u001b[0;31m#print(count_selfloop_conv_mem(layer), count_ideal_conv_mem(image_size, out_image_size, in_channel, out_channel))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                         \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_image_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/memory_predictor/mem_predictor.py\u001b[0m in \u001b[0;36mcount_selfloop_conv_mem\u001b[0;34m(conv_layer_param)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_selfloop_conv_mem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmem_planner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMemoryAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmem_planner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_inFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmem_planner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_mem_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/memory_predictor/self_conv_mem.py\u001b[0m in \u001b[0;36mplace_inFM\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m#print('remove dependent for', out_hi, out_wi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m#self.out_tensors[out_hi][out_wi].print_dependents()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0mnew_free_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_hi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_wi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_all_depedents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_free_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheappush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_in_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/panyj/once-for-all/ofa/nas/memory_predictor/self_conv_mem.py\u001b[0m in \u001b[0;36mremove_all_depedents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m##if ref count becomes 0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# free the mem for this tensor, safe to rewrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdependent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_cnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mnew_free_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FLOPs_constraint = 2000  # MFLOPs\n",
    "workingmem_constraint = 350 # KB\n",
    "P = 100  # The size of population in each generation\n",
    "N = 200  # How many generations of population to be searched\n",
    "r = 0.25  # The ratio of networks that are used as parents for next generation\n",
    "params = {\n",
    "    #'constraint_type': target_hardware, # Let's do FLOPs-constrained search\n",
    "    #'efficiency_constraint': FLOPs_constraint,\n",
    "    'mutate_prob': 0.1, # The probability of mutation in evolutionary search\n",
    "    'mutation_ratio': 0.5, # The ratio of networks that are generated through mutation in generation n >= 2.\n",
    "    'efficiency_predictor': efficiency_predictor, # To use a predefined efficiency predictor.\n",
    "    'accuracy_predictor': acc_predictor, # To use a predefined accuracy_predictor predictor.\n",
    "    'memory_predictor': memory_predictor_self, # To use a predefined working memory predictor\n",
    "    'population_size': P,\n",
    "    'max_time_budget': N,\n",
    "    'parent_ratio': r,\n",
    "}\n",
    "\n",
    "# build the evolution finder\n",
    "finder = EvolutionFinder(**params)\n",
    "\n",
    "# start searching\n",
    "result_lis = []\n",
    "st = time.time()\n",
    "best_valids, best_info = finder.run_evolution_search(FLOPs_constraint, workingmem_constraint, verbose=True)\n",
    "result_lis.append(best_info)\n",
    "ed = time.time()\n",
    "print('Found best architecture with FLOPS <= %.2f M and working mem <= %.2f in %.2f seconds! '\n",
    "      'It achieves %.2f%s predicted accuracy ' %\n",
    "      (FLOPs_constraint, workingmem_constraint, ed-st, best_info[0] * 100, '%'))\n",
    "\n",
    "# visualize the architecture of the searched sub-net\n",
    "_, net_config, FLOPS, workingmem = best_info\n",
    "ofa_network.set_active_subnet(w=net_config['w'], d=net_config['d'], e=net_config['e'])\n",
    "print('Architecture of the searched sub-net:')\n",
    "print(ofa_network.module_str)\n",
    "print('FLOPS',FLOPS,'workingmem', workingmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
